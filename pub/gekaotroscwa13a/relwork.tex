\subsection{Declarative formalization of heuristics}

\paragraph{Programs with Common Sense \cite{mccarthy59a}}
\begin{itemize}
	\item ``first paper on logical AI, i.e. AI in which logic is the method of representing information 
	      in computer memory and not just the subject matter of the program''
	      (McCarthy's web: http://www-formal.stanford.edu/jmc)
	\item ``may be the first paper to propose common sense reasoning ability as the key to AI''
	      (McCarthy's web: http://www-formal.stanford.edu/jmc)
	\item before ``the formal system was the subject matter but the heuristics were all embodied in the program.
	      In this program the procedures will be described as much as possible in the language itself and, 
	      in particular, the heuristics are all so described'' (quotes from the paper)
	\item (from Concepts of Logical AI, http://www-formal.stanford.edu/jmc/concepts-ai.html)
	      ``Declarative Expression of Heuristics proposes reasoning be controlled by domain-dependent and 
	      problem-dependent heuristics expressed declaratively. Expressing heuristics declaratively
	      means that a sentence about a heuristic can be the result of reasoning and not merely something 
	      put in from outside by a person. Josefina Sierra has made some recent progress on it''.
\end{itemize}

\paragraph{Heuristic planning: A declarative approach based on strategies for action selection \cite{sierra04a}}
\begin{itemize}
  \item \textbf{Short Summary}
  \item Forward Chaining Planner that allows declarative formalization of heuristics
        establishing a partial order among actions by means of predicate $better(Action1,Action2,Situation)$.
        Experimental results show that it is slower than TALPlan but finds shorter plans than all systems.
  \item \textbf{Summary}
  \item ``In the paper Programs with Common Sense J. McC described a program called the \textit{advice taker}
        which would represent its knowledge declaratively and would accept advice from its users in the form 
        of declarative sentences. Thes paper gave rise to the \textit{logical approach to Artificial Intelligence}.
        A major drawback of the current logical reasoning systems is their inability to use domain and problem
        dependent heuristic advice to guide their search for solutions. In this paper, we address this problem by presenting
        a scheme for the declarative formalization of heuristics and showing how a general purpose forward chaining 
        planner can use declarative formalizations of heuristics to improve its performance in several domains''.
  \item Forward Chaining Planner in Situation Calculus implemented in Prolog 
  \item Adds predicate $good(Action,Situation)$ s.t. $Action$ is good in $Situation$ if its execution leads to an 
        optimal length plan. This can be represented by simple ASP rules: $occurs(A,S) \leftarrow good(A,S)$.
  \item Adds predicate $bad(Action,Situation)$ s.t. $Action$ is bad in $Situation$ if its execution dont lead to an 
        optimal length plan. This can be represented by simple ASP rules: $\leftarrow occurs(A,S), \ bad(A,S)$.
  \item Adds predicate $better(Action1,Action2,Situation)$ s.t. $Action1$ is preferred to $Action2$ in $Situation$. 
        The predicate determines a partial order among the actions. This is \textit{similar} to hclasp for planning branching on actions.
        For example: \[ _h(A,true,(T*10) + 1,1) \leftarrow action(A), time(T). \] \[ _h(A,true,(T*10)+4,2) \leftarrow action1(A), time(T). \]
        The first rule does forward search, and the second prefers actions of type action1 to the others.         
  \item The planner: If there is a good action, it chooses only it. Else, it explores the subtrees of situations
        that can be generated by applying nonbad actions to the current situation using the partial order established
        by predicate $better$.
  \item As in hclasp, the new predicates may be in the head of rules with body (i.e., they are dynamic).
  \item Compares from a representation point of view the planner with TLPlan and TALPlan, 
        which are based in temporal logic, and 
        Reiter's proposal for GOLOG, but these only allow to force or prune situations (as can be done in ASP), 
        but do not allow to guide the search (as in the paper with $better$ predicate) and as in hclasp.  
  \item Experimental evaluation comparing with TLPlan and TALPlan and R (forward chaining planner from F. Lin).
        Comparing with TLPlan in Blocksworld it is faster and obtains shorter plans.
        Comparing with TALPlan and R, in blocksworld TALPlan is the fastest, the new system is the slowest but finds shorter plans.
        In logistics, TALPlan is the fastest, followed by the new system, which also finds the shorter plans.
  \item \textbf{Comparison}
  \item Planner in Situation Calculus: hclasp applies to a general answer set solver, that can be applied to 
        planning and to other problems.
  \item Forward Chaining: hclasp allows to define other type of planners: forward search on actions, backward search on actions, 
        backward search on fluents, etc.
  \item Different method for formalization of heuristics: hclasp allows to modify sign, level, init, and factor, 
        while in the paper only the partial order among actions can be specified. \textit{But} some partial orders 
        represented in the paper cannot be represented by hclasp, while the orders on actions defined with \textit{true} and 
        \textit{false} can be defined by the paper formalism. For this, the partial order representation is more general, 
        although hclasp with \textit{true} and \textit{false} may be simpler for many domains.
        This is exactly the difference between defining preferences over literals by: (i) circumscription or 
        (ii) a partial order among literals (as in Giunchiglia and Maratea work).        
\end{itemize}
        
\subsection{Impact of heuristics in search}	

\paragraph{The Impact of Branching Heuristics in Propositional Satisfiability Algorithms \cite{silva99a}}
\begin{itemize}
 \item \textbf{Short Summary}
  \item Heuristics may be important, but other issues (backjumping and learning) are essential.
 \item \textbf{Summary}
  \item Comparison of SAT solvers posit and ntab, with no backjumping or learning, 
        with SAT solvers relsat, grasp and sato, with backjumping and learning.
        The latest are much better.
  \item Comparison of grasp with different branching heuristics: 
        bohm, moms, jeroslow-wang, and also: simple heuristics that count the unresolved
        literals in which a literal appears, and also a random heuristic.
  \item Results: Similar results for all heuristics. Random heuristic compares well. 
        The best one is counting literals and allowing some randomization.
  \item \textbf{Comparison}
  \item Shows no difference between general heuristics, 
        we show differences adapting a general heuristic to an specific domain.
  \item My experience with clasp contradicts the paper: 
        berkmin and vsids may lead to different performances.      
        
\end{itemize} 

\subsection{Improving sat and asp solvers modifying the heuristic}	

\paragraph{Learning and Using Domain Specific Heuristics in ASP Solvers \cite{balduccini11b}}
(This paper is an extended version of the other \cite{balduccini10a}, with more experiments).

\begin{itemize}
	\item \textbf{Short Summary}
				Learning offline on instances of an asp encoding.
				Modify the heuristic of smodels to choose the literals that at the same decision level in the training set led to solutions
				without backtracking. Experiments show some improvements. 
	\item \textbf{Summary}
	\item There are cases where the best heuristics perform badly, 
	      typically because the heuristics are general-purpose and may perform bad in domains that substantially deviate from the norm.
	      This may lead to timeouts, which are a big problem (specially for industrial settings).
	\item Method: 1. Learning offline on representative instances. 2. At each choice point, the solver chooses the literals that, 
	      when taken at the same decision level in the training instances, most frequently led to an answer set without backtracking.
	\item Experiments on 2nd ASP competition instances. 
	      In instances easy for smodels, the new system performed similarly or worse. In hard instance for smodels, it was better (19 vs 5 timeouts). 
	      Learning from easy instances and testing in hard instances, the new system was better (18 vs 76 timeouts). 
	      clasp is much much faster, although it timed out twice.
	\item Experiments on usa-advisor: new system is better than smodels with no restarts (10 vs 49 timeouts), 
	      but using restarts the difference is smaller (4 vs 9 timeouts).  
	\item Not implemented in clasp because has variables for bodies, 
	      and because of clause learning.
	\item \textbf{Comparison}
	\item Similar to hclasp: Domain specific heuristics may improve performance.
	\item Similar to hclasp: As Future Work we may apply machine learning to induce heuristic rules, 
	      or to choose the best heuristic rules among some.
	\item Different: hclasp cannot be used to encode the knowledge learned in the paper, 
	      because we cannot refer to the decision levels of the solver.
	\item Different: smodels is hacked in c++ code.
\end{itemize}

\paragraph{$DLV^{MC}$: Enhanced Model Checking in DLV \cite{marive10a}}
\begin{itemize}
	\item \textbf{Short Summary}
	      Use minisat branching on negative literals to do coNP test of DLV. 
	      In the experiments it improves over using satz.
	\item \textbf{Summary}
	\item In DLV to do the coNP test sat the solver SATZ was used. If the formula is sat 
	      a  set of unfounded atoms can be extracted. The performance of DLV depends
	      both on the efficiency of the sat solver and the quality of the returned unfounded set.
	\item Use minisat instead of satz, branching on false literals to get subset minimal solutions.
	\item Experiments on qbf: similar minisat and satz (better than claspd)
	\item Experiments on strategic companies: less coNP checks with minisat and less time (0 vs 3 timeouts).
	      Better than claspd.
	\item \textbf{Comparison}
	\item Fix heuristic sign inside an asp solver. 
	      But this fix is really applied to the sat solver inside dlv, not to the dlv heuristic.
\end{itemize}

\paragraph{Planning as Satisfiability: Heuristics \cite{rintanen12a}}
\begin{itemize}
	\item \textbf{Short Summary}
	\item Planning-specific heuristic for SAT solving. Based on generic principles and properties of plans. Simple, but outperforms vsids and compares to best planners.
	\item \textbf{Summary}
	\item Motivation: (i) Understand why SAT solvers are good at planning, and
				(ii) develop better heuristics for SAT planning.
	\item New Heuristics: Chooses action variables that support current 
				goals based on the current partial valuation of CDCL. 
				Depth-first backward forward chaining inside CDCL.
	\item Results: (i) Simple and understandable heuristic, 
				(ii) Small but hard planning problems, vsids wins, 
				(iii) Unsatisfiable planning instances: vsids wins
				(iv) Benchmark planning problems: outperforms vsids 
				and compares to best planners.
	\item Planning as SAT: (i) Basic encoding with explanatory frame axioms
				(ii) Parallel actions encoding (e-step semantics)
				(iii) Invariants (binary dependencies between fluents)
	\item Top Level Planning Procedure: Sequential Strategy is inefficent because of unsat tests. So use a a parallel algorithm:
	run in parallel the solver for different horizon lengths (allocating different cpu time)
	\item Basic principle: for a given (sub)goal, choose an action that achieves the (sub)goal and that can be taken at the earliest time in which the (sub)goal can become (and remain) true. The principle expresses a preference for simpler and shorter plans. After choosing an action, its preconditions become new subgoals for which supporting actions are found in the same way.
	\item Property of a plan: For every goal literal g(t), either 
				(A) g is true at 0 and persists to t, or
				(B) g is caused by an action at t' ($t'<t$) and persists until t, 
					and the preconditions of a at t' are new goals.
	\item Heuristic method to choose actions: CHOOSE a goal literal at g(t): (A) if g is true at 0 and would persist until t, choose another goal, (B) if g is caused by an action a at t' ($t'<t$) and would persist until t, then the preconditions of a at t' become new goals, 
	(else) if g is false at t' ($t'<t$) and would persist until t, 
					CHOOSE an action a at t' that causes g to true at t'+1.
	\item CHOOSE a goal and CHOOSE an action are the only nondeterministic parts of the algorithm.
	\item Basic setting: goals ordered in a stack, fixed ordering of actions, returns the first action found: Backward chaining depth-first, worse than vsids.
	\item Refinement 1: Idea: choose among many actions for current top goal. Implementation: repeat method to get 40 actions, stop if an action occurs later than the first, select one of them randomly: Better than vsids, still worse than best planners.
	\item Refinement 2: Select the action depending on vsids score, do not fix action ordering, choose the action that is assigned in more instants (going forward), do not stack goals (choose the goal that persists backwards to an earlier instant): Outperforms vsids, compares to best planners.
	\item Main idea: combine focus to utilize learned clauses (backward chaining algorithm) with variation to avoid getting stuck (refinements for flexibility).
	\item \textbf{Comparison}
	\item Similar: modify heuristic to improve search efficiency. Both improve vsids on SAT instances, but are worse on UNSAT ones (it would be interesting to find good heuristic for unsat).
	\item Similar: We both do backward search from goals, but in the paper the branch is on actions and fluent values are deduced, while we do branch on fluents, and actions are deduced. We also tried other heuristics (forward and backward search with actions, but they did not work so well).
	\item Similar: combine specific heuristic with general-purpose heuristic: in the paper first some actions are selected, then the one with best vsids score is chosen. We do the same with fluents (among the ones of highest level, we choose the one with best vsids score).
  \item Different: Planning Method: ours is simpler, and surely slower: same basic encoding, but no parallel actions, no invariants, and sequential strategy (but we will make it :))	
  \item Different: SAT (Planning), we do ASP (for any NP problem).
	\item Different: We propose general framework for heuristic programming, in the paper some heuristics are applied: so we provide a general framework to do rintanen's paper (BUT We cannot formalize the paper heuristic because we cannot refer to undefined valued of literals to trigger rules).
	\item Different: Hacking solver code, no declarative formalization of heuristic, for us it is very easy to try new heuristics, and to modify them for specific domains (maybe automatically with machine learning techniques (?)).
\end{itemize}

\begin{itemize}
	\item \textbf{Short Summary}
	\item Present the method of \cite{rogima10a} with 
	      the extension to quantitative preferences and formulas.
	      Also they introduce the other method based in generate and test (as clasp for minimize) from ECAI 2008.
	\item \textbf{Summary}
	\item The heuristic method has two drawbacks: imposes an order on the heuristic and needs exponential space 
				to compute all models.
	\item The generate-and-test method: compute a model, print it if it is optimal (check this with a sat test), continue the search for all models.
	\item The computation of all models is extended to projection on some variables, so if two models differ only in no-preferred variables, 
				only one is found.
\end{itemize}

\paragraph{Introducing preferences in Planning as SAT \cite{giumar11a}}
\begin{itemize}
	\item \textbf{Short Summary}
	\item Apply the method of \cite{rogima10a} to SAT planning with preferences. 
				The system return plans of better quality than basic satplan. 
				The system is competitive with sgplan, the 
				best of the simplePreferences on planning competition. When there are not many preferences, 
				the system FOR CARDINALITY MINIMIZATION compares to basic satplan. 
				When there are many (f.e., to minimize the plan length) sometimes it compares, 
				and only in some cases when there are many many it is worse.
				The system applied to subset minimization often finds solutions close to the optimal cardinality.
	\item \textbf{Summary}
	\item Experiment 1: Non conflicting soft goals. Planning problems from planning competition. 
				A plan is valid if it satisfies one goal, and all goals are considered soft goals (each counts 1 point).
				The new system for cardinality finds solutions of quality similar to sgplan, 
				and the new system for subset finds solutions similar to those (just a bit worse that for cardinality in some cases).
				Time also compares to sgplan, and the new system for cardinality timeouts 18 times more than the basic satplan.
				For subset it also times out 18 times (the same!) more than the basic system.
				The good results compared to the basic system can be explained by the fact that there were few preferences:
				at most there were 70 goals, and a majority of the instances instances contained at most 30 goals.
	\item Experiment 2: Conflicting soft goals. Planning problems from the simplePreferences planning competition.
				Each goal gets one point. They only test the cardinality system. Pathways domain: similar results. 
				Storage domain: new system is slower but gets better quality solutions. For trucks and openstack 
				it was too difficult already for minisat, so, no way. Similar results for conflicting goals in Experiment 3.			
	\item Experiments minimizing plan length. For subset minimization a total order among actions is set (to further constrain the heuristic).
				The new systems (for cardinality and subset) get smaller solutions. 
				For cardinality it is similar to satplan if actions are less than half of the atoms of the problem, and then it is slower.
				For subset it compares, sometimes it is faster, sometimes slower or similar.
	\item \textbf{Comparison}
	\item We applied the method to improve efficiency in planning (as Rintanen), 
				here they apply the method for optimization in planning.
	\item IMPORTANT: In many cases with not many preferences, cardinality minimization comes almost for free.
\end{itemize}


\paragraph{Last Work: E. Di Rosa, E. Giunchiglia, B. O'Sullivan. 
Combining approaches for solving Satisfiability problems with Preferences and their Evaluation. 
Accepted to the 10th Workshop on Preferences and Soft Constraints (SOFT'10).}
\begin{itemize}
	\item \textbf{Short Summary}
				Do branch and bound modifying the sign of the chosen literals according to the preferences.
				Improves over the other two methods.
	\item \textbf{Summary}
	\item Idea: Combine the heuristic method (HS) with the branch and bound one (they call it the blocking formula method, BF).
				Use the BF method but when branching on preferred literals, choose the sign according to the preferences.
				If you prefer a positive literal, branch on the positive literal. If you prefer the negative, branch on the negative.
				Else, do as usual.
	\item Justification: no ordering on the heuristic, so the negative theoretical results of Jarvisalo et al. do not apply.
				And by fixind the polarity it is expected to find less intermediate models.
	\item Implemented in system SAT\&PREF, that allows to use the three methods (HS, BF and SAT\&PREF).
				For HS method the preferences are specified by the transitive reduction of the preferences (ie., just give the basic preferences), 
				and for the other two the transitive closure of the preference relation must be given (ie., if two literals are (possibly 
				transitively) related, then it must be so stated).
	\item Experiments (only qualitative preferences) from competitions: 
				HS and BF have similar results (HS has more timeouts in 2 domains, and the same for BF).
				SAT\&PREF improves them both and computes less intermediate models than BF.
	\item Note: In the 2008 ECAI paper on the BF method they included the same experiments as here, but there the BF method
				was better than HS, while here they are similar.
	\item Experiments from random instances with random qualitative preferences: HS is the worst, 
				BF is close to SAT\&PREF, but this last is better in general, specially in the harder instances.
	\item \textbf{Comparison}
	\item This is what we do for cardinality minimization: branch and bound modifying the heuristic sign.
				But they do it for qualitative optimization.
	\item Of course, we do ASP and this is SAT.
\end{itemize}

\paragraph{Using the Davis and Putnam procedure for an efficient computation of preferred models \cite{cacacale96a}}
\begin{itemize}
	\item \textbf{Short Summary}
				Modify heuristic of DPLL to find preferred models. For enumeration add clause to delete worse models than the one just found.
	\item \textbf{Summary}
	\item Preferences Definition: Given a set of literals, a model is preferred if it is subset maximal wrt those literals.
	\item Method to compute one model: Branch first on unassigned preferred literals.
	\item Method to compute all models: Add a constraint to delete worse models than the one just found.
	\item Note: they do projection on the preferred literals.
	\item They apply the method to ATMS and Closed World Reasoning. 
				For ECWA (parallel circumscription) they do not handle fixed atoms, and they do not consider prioritized circumcription.
	\item Given a set B of clauses and a literal d, they mention four kinds of algorithms: (i) model finding: finding a minimal model of B, 
				(ii) model checking: check whether an interpretation is a minimal model of B,
				(iii) minimal entailment: is d true in all minimal models of M?
				and (iv) minimal membership: is d true in at least one minimal model of B?
	\item \textbf{Comparison}
	\item SAT and enumeration, we do ASP and maybe enumeration.
	\item We can do prioritized circumscription, in the paper they did parallel circumscription with no fixed atoms.
\end{itemize}


\subsection{Complexity}	

\paragraph{The Complexity of Optimal Planning and a More Efficient
               Method for Finding Solutions \cite{raygins08}}
\begin{itemize}
	\item \textbf{Summary}
	\item Modify SATPLAN this way: (i) Add variables $G_i$ for each time instant $i$ and add clauses 
				that represent that $G_i$ is true iff all goals are satisfied at time $i$.
				(ii) Modify the SAT solver to branch in order on $G_1$, $G_2$, \ldots, so that a minimal length plan 
				can be found by a unique SAT call.
	\item In the experiments they improve SATPLAN results, but they do not explain much.
	\item Theory: Introduce the complexity notion of capability of an algorithm, that represents the class of problems that can be solved
				by an algorithm. DPLL is $\Delta_2$-capable because it can solve any problem in $\Delta_2$, 
				and it cannot solve any problem in a higher class unless the polynomial hierarchy collapses.
\end{itemize}


\subsection{Preferences in ASP?}	


%\subsection{Subsection}	

%\paragraph{Titel and Cite}
%\begin{itemize}
%	\item \textbf{Short Summary}
%	\item \textbf{Summary}
%	\item \textbf{Comparison}
%\end{itemize}

\subsection{Subsection}	

\paragraph{Titel and Cite}
\begin{itemize}
	\item \textbf{Short Summary}
	\item \textbf{Summary}
	\item \textbf{Comparison}
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
